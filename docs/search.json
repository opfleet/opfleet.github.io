[
  {
    "objectID": "posts/PerceptronPost/index.html",
    "href": "posts/PerceptronPost/index.html",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "Abstract\nIn this blog post, I am aiming to construct an implementation of the perceptron algorithm and then test its efficacy on a synthetic set of linearly separable data. I will then use the popular Iris dataset that can be found on Kaggle as a prime example of a linearly separable and non-linearly separable dataset. The Iris dataset is composed of three labels, one of which is linearly separable from the rest of the data, and two which are not. I will use this characteristic to use the dataset as both a linearly separable and non-linearly separable set in my exploration.\nHere is a link to my perceptron.py file, which contains my implementation of the perceptron algorithm that I use throughout this blog post.\nHere is my implementation of the perceptron.grad() function:\ndef grad(self, X, y):\n        s = self.score(X)\n        return torch.where(s*y &lt; 0, y @ X, 0.0)\nEach line corresponds to the two main lines of math in the perceptron algorithm: \\[s_i = w \\cdot x_i \\] and return the vector \\[ \\mathbb{1}[s_iy_i &lt; 0]y_ix_i\\]\nThe first line is fairly self-explanatory; my perceptron.score() function takes in the input x_i and returns its dot product against the weight value w, as defined by the algorithm. For the second line, the combination of the double-struck one and the condition it is multiplied against are the mathematical equivalent to an if statement, in that if the condition is true, multiply the following expression by 1, and if the condition is false, multiply the following expression by 0. Thus, I was able to use a torch.where() function to implement this equation, as it uses a condition to assign different values, depending on the evaluation of the condition.\n\n\nPart A: Implement Perceptron\nIn this section, I will be utilizing my perceptron algorithm contained in the file perceptron.py on arbitrary linearly-separable data, to ensure that my implementation works properly.\n\n%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\nHere is a visualization of my linearly-separable data, used to check my perceptron implementation.\n\nimport torch\nfrom matplotlib import pyplot as plt\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n    y = y.type(torch.FloatTensor)\n    return X, y\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [-1, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\nfig, ax = plt.subplots(1, 1, figsize = (4, 4))\nax.set(xlim = (-1, 2), ylim = (-1, 2))\nplot_perceptron_data(X, y, ax)\n\n\n\n\n\n\n\n\nHere I am running my perceptron algorithm on the data, and printing the loss at each iteration. We can see how the loss begins at 0.5, and decreases until it reaches 0, where my algorithm has terminated upon finding a separating line between the two classes.\n\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\n\nloss = 1.0\n\n# for keeping track of loss values\nloss_vec = []\n\nn = X.size()[0]\n\nwhile loss &gt; 0.0: # dangerous -- only terminates if data is linearly separable\n    \n    # not part of the update: just for tracking our progress    \n    loss = p.loss(X, y) \n    loss_vec.append(loss)\n    \n    # pick a random data point\n    i = torch.randint(n, size = (1,))\n    x_i = X[[i],:]\n    y_i = y[i]\n\n    \n    # perform a perceptron update using the random data point\n    opt.step(x_i, y_i)\n\nprint(loss_vec)\n\n[tensor(0.5000), tensor(0.5000), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.0900), tensor(0.2600), tensor(0.2600), tensor(0.1700), tensor(0.1700), tensor(0.1700), tensor(0.1700), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.3167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.0167), tensor(0.)]\n\n\nHere is a visualization showing the loss at each iteration of the perceptron update.\n\nplt.figure(figsize= (8,8))\nplt.plot(loss_vec, color = \"slategrey\")\n\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\n\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\", title = \"Perceptron Loss on Linearly Separable Data\")\n\n\n\n\n\n\n\n\n\n\nPart B: Experiments\nIn this section, I will be using the famous linearly-separable Iris data set from R.A. Fisher’s 1936 paper The Use of Multiple Measurements in Taxonomic Problems from the UCI Machine Learning Repository. This data set contains three iris species, each with 50 samples and multiple features for each data point. One species of iris is linearly separable from the other two. I will be illustrating the following claims concerning perceptron algorithms: 1. When using 2D data, if the data is linearly separable, then the perceptron will converge to weight vector w that describes a separating line. I will choose the setosa species of iris as a binary label, as it is linearly separable from the rest of the data. 2. When using 2D data, if the data is not linearly separable, the perceptron algorithm will not settle on a final value of w, but will instead run until the maximum number of iterations is reached, without achieving perfect accuracy (assumption that 1000 iterations is sufficient). I will choose the versicolor species of iris as a binary label, as it is not linearly separable from the rest of the data. 3. The perceptron algorithm will be able to work in more than 2 dimensions of data. I will show this by running my algorithm on data with at least 5 features. While the Iris dataset only has 4 features, I will add a dummy 5th feature that is constant between every data point, thereby making the dataset 5th-dimensional, while still maintaining the linear separability of the dataset (when using the setosa species as a binary label).\nFirst, I will load the Iris dataset into the Jupyter Notebook.\n\nimport pandas as pd\ndf = pd.read_csv('Iris.csv')\nprint(df.head())\n\n   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n0   1            5.1           3.5            1.4           0.2  Iris-setosa\n1   2            4.9           3.0            1.4           0.2  Iris-setosa\n2   3            4.7           3.2            1.3           0.2  Iris-setosa\n3   4            4.6           3.1            1.5           0.2  Iris-setosa\n4   5            5.0           3.6            1.4           0.2  Iris-setosa\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nIn the following visualization, we can see that the Setosa species of Iris flower is linearly separable from the other two species (Versicolor and Virginica), when looking at the features Sepal Length and Petal Length. We can also see that using these two features, that the Versicolor and Virginica species are not linearly separable from one another. Since we are only using two features, we can consider this data to be 2 dimensional. Thus, we will try to prove our first two claims using the Sepal Length and Petal Length features of this dataset.\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\nplot1 = sns.scatterplot(data= df, x= 'SepalLengthCm', y= 'PetalLengthCm', hue= 'Species', ax= ax)\nplot1.set(xlabel= 'Sepal Length (cm)', ylabel= 'Petal Length (cm)', title= \"Sepal Length vs. Petal Length\")\nplot1\n\n\n\n\n\n\n\n\nNow to prep our data. We will only be considering the features Sepal Length and Petal Length in our first two claims. Additionally, since we want to see whether one class is linearly separable from the other two, we will transform the ‘Species’ feature into a binary value representing whether the given Iris data point is of the Setosa species or not.\n\nx1 = torch.tensor(df['SepalLengthCm'].values)\nx2 = torch.tensor(df['PetalLengthCm'].values)\nbias = torch.ones(x1.shape[0])\nX = torch.stack((x1, x2, bias), -1)\n\nspecies_setosa = df['Species'] == 'Iris-setosa'\ny = torch.from_numpy(species_setosa.values)\n\nX = X.type(torch.FloatTensor)\ny = y.type(torch.FloatTensor)\n\ny = torch.where(y == 1.0, 1.0, -1.0)\n\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 100)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x,y,**kwargs)\n\nAs we can see in the following visualization, my implementation of the perceptron algorithm takes 13 update steps to find a separating hyperplane between the setosa species and the rest of the data, when considering the features Sepal Length and Petal Length.\n\ntorch.manual_seed(2)\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\np.loss(X, y)\n\n# set up the figure\nplt.rcParams['figure.figsize'] = (14, 9)\nfig, axarr = plt.subplots(3, 5, sharex= True, sharey= True)\nmarkers = ['o', ',']\nmarker_map = {-1 : 0, 1 : 1}\n\ncurrent_ax = 0\nloss = 1.0\nmax_iter = 1000\n\n# for keeping track of loss values\nloss_vec = []\n\ncurr_iter = 0\n\nwhile loss &gt; 0.0 and curr_iter &lt; max_iter: #if data is not linearly separable, terminates after 1000 iterations\n    \n    ax = axarr.ravel()[current_ax]\n\n    # save old value of w for plotting\n    old_w = torch.clone(p.w)\n    \n    # update step on random data point\n    rand_point = torch.randint(X.shape[0], size = (1,))\n    x_i = X[[rand_point],:]\n    y_i = y[rand_point]\n    local_loss = opt.step(x_i, y_i)\n\n    # if change was made, plot old and new decision boundaries\n        # adds new loss to loss_vec for plotting\n    if local_loss &gt; 0:\n        plot_perceptron_data(X, y, ax)\n        draw_line(old_w, x_min = 4, x_max = 8, ax = ax, color = 'black', linestyle = 'dashed')\n        loss = p.loss(X, y).item()\n        loss_vec.append(loss)\n        draw_line(torch.clone(p.w), x_min = 4, x_max = 8, ax = ax, color = 'black')\n        ax.scatter(X[rand_point, 0], X[rand_point, 1], color = 'black', facecolors = 'none', edgecolors = 'black', marker = markers[marker_map[y[rand_point].item()]])\n        ax.set_title(f'loss = {loss:.3f}')\n        ax.set(xlim = (4, 8), ylim = (0, 8))\n        ax.grid(True)\n        current_ax += 1\n    curr_iter += 1\n    plt.tight_layout\n\n\n\n\n\n\n\n\nHere is a graph showing the evolution of the loss over the course of the perceptron algorithm. Notice that the graph terminates before the maximum number of iterations at step 13. This shows again that the perceptron converged in 13 update steps.\n\nplt.figure(figsize= (8,8))\nplt.plot(loss_vec, color = \"slategrey\")\n\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\n\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\", title = \"Perceptron Loss on Linearly Separable Data 2 Dimensions\")\n\n\n\n\n\n\n\n\nNow, we will do that again on data that is not linearly separable, that is, when the predictive class is either the Versicolor or Virginica species of Iris flower (we will select the Versicolor species arbitrarily here). Again, I am creating a binary label of whether a given data point is of the Versicolor species or not.\n\nspecies_versicolor = df['Species'] == 'Iris-versicolor'\ny2 = torch.from_numpy(species_versicolor.values)\n\ny2 = y2.type(torch.FloatTensor)\n\ny2 = torch.where(y2 == 1.0, 1.0, -1.0)\n\nIn this visualization, I show the decision boundary of the final iteration of my perceptron algorithm (at the maximum iteration step, 1000). It is apparent that the decision hyperplane does not cleanly separate the Versicolor species from the rest of the data.\n\ntorch.manual_seed(34)\n\n# instantiate a model and an optimizer\np2 = Perceptron() \nopt2 = PerceptronOptimizer(p2)\n\nloss = p2.loss(X, y2).item()\nmax_iter = 1000\n\n# for keeping track of loss values\nloss_vec = []\n\nn = X.shape[0]\ncurr_iter = 0\n\nultimate_w = torch.zeros_like(p2.w)\n\nwhile loss &gt; 0.0 and curr_iter &lt;= max_iter: #if data is not linearly separable, terminates after 1000 iterations\n    \n    # update step on random data point\n    rand_point = torch.randint(n, size = (1,))\n    x_i = X[[rand_point],:]\n    y2_i = y2[rand_point]\n    opt2.step(x_i, y2_i)\n\n    loss = p2.loss(X, y2).item()\n    loss_vec.append(loss)\n\n    if curr_iter == max_iter:\n        ultimate_w = torch.clone(p2.w)\n\n    curr_iter += 1\n\nfig, ax = plt.subplots(1, 1, figsize = (8, 8))\nax.set(xlim = (4, 8), ylim = (0, 8))\nax.set_title(f'Loss = {loss:.3f}')\nax.grid(True)\nplot_perceptron_data(X, y2, ax)\ndraw_line(ultimate_w, x_min = 2, x_max = 8, ax = ax, color = \"red\")\n\n\n\n\n\n\n\n\nAs can be seen in the following visualization, the perceptron algorithm iterates until the max_iter limit of 1000, and does not terminate at a loss of 0.0. This means that the perceptron has not found a hyperplane that perfectly separates the target class from the rest of the data.\n\nplt.figure(figsize= (8,8))\nplt.plot(loss_vec, color = \"slategrey\")\n\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\n\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\", title = \"Perceptron Loss on Non-Linearly Separable Data with 2 Dimensions\")\n\n\n\n\n\n\n\n\nHere I am using all four of the features in the Iris data set and constructing a dummy feature with the value of 1 across all data points. In this way, I have converted the data to be fifth-dimensional, and kept its linear-separability, when classifying the binary Setosa species label. Consequently, I am reverting back to the binary Setosa label (labeling whether the data point belongs to the Setosa class or not).\n\nx1 = torch.tensor(df['SepalLengthCm'].values)\nx2 = torch.tensor(df['PetalLengthCm'].values)\nx3 = torch.tensor(df['SepalWidthCm'].values)\nx4 = torch.tensor(df['PetalWidthCm'].values)\nx5 = torch.zeros(x1.shape[0]) #arbitrary feature to create a fifth feature\nbias = torch.ones(x1.shape[0])\n\nX = torch.stack((x1, x2, x3, x4, x5, bias), -1)\n\nspecies_setosa = df['Species'] == 'Iris-setosa'\ny = torch.from_numpy(species_setosa.values)\n\nX = X.type(torch.FloatTensor)\ny = y.type(torch.FloatTensor)\n\ny = torch.where(y == 1.0, 1.0, -1.0)\n\n\n# instantiate a model and an optimizer\np3 = Perceptron() \nopt3 = PerceptronOptimizer(p3)\n\nloss = p3.loss(X, y).item()\nmax_iter = 1000\n\n# for keeping track of loss values\nloss_vec = []\n\nn = X.shape[0]\ncurr_iter = 0\n\nwhile loss &gt; 0.0 and curr_iter &lt;= max_iter: #if data is not linearly separable, terminates after 1000 iterations\n    \n    # update step on random data point\n    rand_point = torch.randint(n, size = (1,))\n    x_i = X[[rand_point],:]\n    y_i = y[rand_point]\n    opt3.step(x_i, y_i)\n\n    loss = p3.loss(X, y).item()\n    loss_vec.append(loss)\n\n    curr_iter += 1\n\nIn the following visualization that plots the evolution of the loss against the number of update steps that my perceptron implementation makes, it can be seen that the algorithm converges to a loss of 0.0 at around step 27. This shows that the perceptron algorithm has found a hyperplane that separates the data belonging to the Setosa species from the rest of the data. Therefore, the dataset that the perceptron is acting upon is linearly separable.\n\nplt.figure(figsize= (8,8))\nplt.plot(loss_vec, color = \"slategrey\")\n\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\n\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"loss\", title = \"Perceptron Loss on Linearly Separable Data with 5 Dimensions\")\n\n\n\n\n\n\n\n\n\n\nPart D: Writing\nQuestion: What is the runtime complexity of a single iteration of the perceptron algorithm?\nThe runtime complexity of the perceptron algorithm is \\(O(n*p)\\), where \\(n\\) is the number of data points and \\(p\\) is the number of features. For each data point, the algorithm computes the dot product of the feature vector with the weight vector, and updates the weights if a misclassification occurs. If \\(n\\), the number of data points were to increase, the algorithm would need to perform more dot products, linearly increasing the number of calculations done. If \\(p\\), the number of features were to increase, the algorithm would need to make more calculations within each dot product for every data point, again linearly increasing the runtime.\n\n\nConclusion\nIn this blog post, I constructed a working implementation of the perceptron algorithm and first tested it successfully against a synthetic linearly separable dataset. I then experimented with my algorithm using the Iris dataset, which could be modified to be a linearly separable dataset, a non-linearly separable dataset (depending on the class being classified), or a dataset with five features. Through my experimentation, I found that my perceptron worked correctly against a linearly separable dataset with 2 dimensions, predictably did not terminate on a non-linearly separable dataset with 2 dimensions, and successfully found a hyperplane that separated a linearly separable dataset with 5 dimensions."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Oscar",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Implementing the Perceptron Algorithm\n\n\n\n\n\nIn this post, I will be completing an implementation of the perceptron algorithm and testing it in several experiments.\n\n\n\n\n\nApr 9, 2024\n\n\nOscar Fleet\n\n\n\n\n\n\n\n\n\n\n\n\nWhose Costs?\n\n\n\n\n\nMy Blog Post for Homework 2\n\n\n\n\n\nApr 1, 2024\n\n\nOscar Fleet\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer’s Penguins\n\n\n\n\n\nMy Blog Post for Homework 1: Classifying Palmer’s Penguins\n\n\n\n\n\nFeb 21, 2024\n\n\nOscar Fleet\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/LoanPost/index.html",
    "href": "posts/LoanPost/index.html",
    "title": "Whose Costs?",
    "section": "",
    "text": "Abstract\nThis blog post presents the development and application of a machine learning-based logistic regression model to assess the risk of loan default associated with loan applicants and subsequently determining the optimal threshold for maximizing profit for a bank. The model leverages various applicant features to assign risk scores, enabling precise categorization of applicants into high and low-risk groups. Through further analysis, the optimal threshold for loan approval is identified, balancing the trade-off between minimizing risk and maximizing profitability. By utilizing this threshold, the model decides to approve or deny loans based on the risk scores of individual applicants. Upon training the model, the trained weights of the model showed that the most influential features for a potential loan applicant were the loan amount and the applicant’s income.\n\n\nPart A: Grab the Data\nHere I import the data and get a quick snapshot of the column names and types of data within it.\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n\ndf_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n\n\n\n\n\n\n\nPart B: Explore the Data\nCreate at least two visualizations and one summary table in which you explore patterns in the data. You might consider some questions like:\n\nHow does loan intent vary with the age, length of employment, or homeownership status of an individual?\nWhich segments of prospective borrowers are offered low interest rates? Which segments are offered high interest rates?\nWhich segments of prospective borrowers have access to large lines of credit?\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nFor my first visualization, I created a density plot of the initial loan rate of a loan applicant vs. their income, with color mapping representing whether the person had a past loan default in their history. One trend that is most apparent is the clear divide between loan applicants that have had a past default and those that haven’t. Across all income levels, there is a seemingly constant difference regarding initial loan rates between those who have had a past default and those who have not. Those who have had a past loan default on their file tend to have an initial loan rate of 10% or higher, while those who have not tend to have a 10% rate or lower. The rates for those with a past loan default seem to concentrate around 12.5% and 7.5% for those without a past default, regardless of income level.\n\nplot1 = sns.displot(data= df_train, x= 'person_income', y= 'loan_int_rate', hue= 'cb_person_default_on_file')\nplt.xscale('log')\n\n# This code is not working, it just creates a separate legend that doesn't have labels\n#plt.legend(title= 'History of Default', labels= [\"No\", \"Yes\"])\n\nplot1.set(xlim= (0, 1000000))\nplot1.set(xlabel= \"Person's Income (Log Scale)\", ylabel= \"Initial Loan Rate\", title= 'Initial Loan Rate vs. Income')\nplt.show()\n\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\axisgrid.py:39: UserWarning: Attempt to set non-positive xlim on a log-scaled axis will be ignored.\n  ax.set(**kwargs)\n\n\n\n\n\n\n\n\n\nI then plotted a catplot of a loan applicants income against their home ownership types. Again, there did not seem to be a strong trend, but there was a slightly higher median of income for loan applicants renting their homes as opposed to mortgaging or owning. Perhaps this correlates to a trend in which a person needs a larger income in order to afford to rent certain types of homes (i.e. expensive apartments or condos). Like the weak correlation above, it seems that not much can be extraploated from this visualization that could prove helpful to prediciting loan default rates of a given person.\n\nplot2 = sns.catplot(data= df_train, x= 'person_home_ownership', y= 'loan_int_rate', kind= \"boxen\")\nplot2.set(xlabel= \"Home Ownership Type\", ylabel= \"Initial Loan Rate\", title= 'Income Across Home Ownership Types')\nplot2\n\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\n\n\n\n\n\n\n\n\nFor the third visualization, I created a catplot that mapped one’s initial loan rate against whether or not they have had a past loan default. Here, I found a strong trend of higher initial loan rates for those who have previously defaulted on a loan. This correlation is intuitive, as most banks would want to protect their interests from possible future defaults through higher loan rates, and people who have defaulted on loans in the past are often thought to be more likely to default in the future, than those who have never defaulted on a loan.\n\ntemp = df_train.copy()\ntemp['cb_person_default_on_file'] = temp['cb_person_default_on_file'].str.replace('Y', 'Past Default')\ntemp['cb_person_default_on_file'] = temp['cb_person_default_on_file'].str.replace('N', 'No Default')\n\n\nplot3 = sns.catplot(data= temp, x= 'cb_person_default_on_file', y= 'loan_int_rate', kind= 'boxen')\nplot3.set(xlabel= \"History of Loan Default\", ylabel= \"Initial Loan Rate\", title= 'Initial Loan Rate vs. Loan Default History')\nplot3\n\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\n\n\n\n\n\n\n\n\nI then had the idea to separate all of the loan applicants by age group, as perhaps there were trends that existed between them. I chose the categories of &lt;30, 30-50, 50-70, 70-90, and 90+. I then compared the number of loan applications from each group, and found that the dataset is mostly comprised of loan applications from people younger than 30, at that there are little to no applications from people older than 50 in the data set.\n\nbins= [0, 30, 50, 70, 90, 150]\nlabels= [\"&lt;30\", \"30-50\", \"50-70\", \"70-90\", \"90+\"]\ndf_train['person_age_group'] = pd.cut(df_train[\"person_age\"], bins=bins, labels=labels, right=False)\n\n\nplot3 = sns.catplot(df_train, x= \"person_age_group\", y= None, kind= 'count')\nplot3.set(xlabel= 'Age Group', ylabel= 'Count', title= \"Number of Loans by Age Group\")\nplot3\n\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grouped_vals = vals.groupby(grouper)\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grouped_vals = vals.groupby(grouper)\n\n\n\n\n\n\n\n\n\nI then wanted to see the distribution of loan intents across age groups, so I created the following summary table. Within the &lt;30 group, the most common intent was education, the least common was home improvement, and the rest were mostly comparable. This is intuitive as most young people are focused on going to college or graduate school and take out loans to do so; they also often do not have houses to make improvements upon during this time in their lives. The 30-50 group generally had an even distribution of loan intents. The 50-70 group saw a large amount of loan applications with the intent of ‘personal’. Perhaps this is due to most of these people being retired, yet living outside of their means, and are thus relying on the money of bank loans to pay for some of their lifestyles instead of their old incomes.\n\nsum_table = df_train.groupby([\"person_age_group\", 'loan_intent']).size()\nsum_table\n\nC:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_44992\\2851417689.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  sum_table = df_train.groupby([\"person_age_group\", 'loan_intent']).size()\n\n\nperson_age_group  loan_intent      \n&lt;30               DEBTCONSOLIDATION    3028\n                  EDUCATION            4001\n                  HOMEIMPROVEMENT      1881\n                  MEDICAL              3429\n                  PERSONAL             3129\n                  VENTURE              3340\n30-50             DEBTCONSOLIDATION    1114\n                  EDUCATION            1106\n                  HOMEIMPROVEMENT      1001\n                  MEDICAL              1363\n                  PERSONAL             1156\n                  VENTURE              1239\n50-70             DEBTCONSOLIDATION      35\n                  EDUCATION              18\n                  HOMEIMPROVEMENT        20\n                  MEDICAL                35\n                  PERSONAL              118\n                  VENTURE                34\n70-90             DEBTCONSOLIDATION       1\n                  EDUCATION               0\n                  HOMEIMPROVEMENT         0\n                  MEDICAL                 7\n                  PERSONAL                4\n                  VENTURE                 0\n90+               DEBTCONSOLIDATION       0\n                  EDUCATION               2\n                  HOMEIMPROVEMENT         0\n                  MEDICAL                 1\n                  PERSONAL                1\n                  VENTURE                 1\ndtype: int64\n\n\n\n\nPart C: Build a Model\nPlease use any technique to construct a score function and threshold for predicting whether a prospective borrower is likely to default on a given loan. You may use all the features in the data except loan_grade (and the target variable loan_status), and you may choose any subset of these. There are several valid ways to approach this modeling task:\n\nChoose features and estimate entries of a weight vector w by hand (this is allowed but not recommended).\n(Recommended): Choose your features, estimate new ones if needed, and fit a score-based machine learning model to the data. My suggestion is LogisticRegression. Once you have fit a logistic regression model, the weight vector w is stored as the attribute model.coef_.\n\nI suggest that you try several combinations of features, possibly including some which you create, and test out which combinations work best with cross-validation.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\n\nHere I am removing the loan_grade and loan_status features from the dataset, saving loan_status as the target variable for later use. Additionally, I created ‘dummy’ variables for all of the qualitative features (e.g., person_home_mortgage, loan_intent, etc.), so that it can be processed by my logistic regression model.\n\n# HERE one-hot encode all of the qual variables\n\ndef prepare_data(df):\n  df = df.dropna()\n  y = df[\"loan_status\"]\n  df = df.drop([\"loan_status\", \"loan_grade\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(df_train)\n\n\n# feature names\nfeatures = X_train.columns\nLR = LogisticRegression(max_iter= 10000)\nLR.fit(X_train[features], y_train)\n\nLogisticRegression(max_iter=10000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=10000)\n\n\nHere I show the optimal weights for all of the features that the model was trained on. It seems that the most important factors were the loan amount and the applicant’s income.\n\ncoefficients = LR.coef_\n\nweights_table = pd.DataFrame({'Feature': features, 'Weight': coefficients[0]})\nweights_table.sort_values('Weight', ascending= False)\n\n\n\n\n\n\n\n\nFeature\nWeight\n\n\n\n\n3\nloan_amnt\n1.065581e-04\n\n\n4\nloan_int_rate\n9.498579e-08\n\n\n10\nperson_home_ownership_RENT\n8.072591e-09\n\n\n18\ncb_person_default_on_file_Y\n7.272047e-09\n\n\n11\nloan_intent_DEBTCONSOLIDATION\n2.680009e-09\n\n\n5\nloan_percent_income\n2.549965e-09\n\n\n13\nloan_intent_HOMEIMPROVEMENT\n1.839150e-09\n\n\n14\nloan_intent_MEDICAL\n1.332706e-09\n\n\n21\nperson_age_group_50-70\n1.216076e-10\n\n\n8\nperson_home_ownership_OTHER\n5.824537e-11\n\n\n23\nperson_age_group_90+\n-2.296252e-12\n\n\n22\nperson_age_group_70-90\n-1.399148e-11\n\n\n20\nperson_age_group_30-50\n-8.286292e-10\n\n\n15\nloan_intent_PERSONAL\n-1.414263e-09\n\n\n19\nperson_age_group_&lt;30\n-1.656899e-09\n\n\n12\nloan_intent_EDUCATION\n-3.018828e-09\n\n\n16\nloan_intent_VENTURE\n-3.798981e-09\n\n\n9\nperson_home_ownership_OWN\n-3.939349e-09\n\n\n7\nperson_home_ownership_MORTGAGE\n-6.571695e-09\n\n\n17\ncb_person_default_on_file_N\n-9.652256e-09\n\n\n6\ncb_person_cred_hist_length\n-1.225154e-08\n\n\n2\nperson_emp_length\n-2.492166e-08\n\n\n0\nperson_age\n-6.362318e-08\n\n\n1\nperson_income\n-4.057367e-05\n\n\n\n\n\n\n\n\nLR.score(X_train[features], y_train)\n\n0.8080062862880342\n\n\n\n\nPart D: Find a Threshold\nGiven assumptions for our model: 1. If the loan is repaid in full, the profit for the bank is:\n$\\text{loan\\_amt}\\times(1+0.25\\times\\text{loan\\_int\\_rate})^{10} - \\text{loan\\_amt}$\n\nIf the borrower defaults on the loan, the “profit” is:\n\\(\\text{loan\\_amt}\\times(1+0.25\\times\\text{loan\\_int\\_rate})^{3}-(1.7\\times\\text{loan\\_amt})\\)\n\nAfter training my model, I had it predict the probabilities of each data point belonging to class 0 or class 1, i.e., the receiver of the bank loan either repaying or defaulting on their loan. I then created the ‘profit_likeli’ feature within the training set, which represents the probability of the loanee fully repaying the bank loan, thereby making the bank a profit. Instead of creating a “risk” score to quantify how likely the loanee is to default, I chose this metric, as the prospective loss due to a loan default is expressed as an impact on the profit in the given assumptions of the model.\n\nfrom sklearn.metrics import confusion_matrix\n\ntrain_preds = LR.predict_proba(X_train[features])\nX_train[\"profit_likeli\"] = train_preds[:, 0]\n\nI followed the equations above to create new columns in the dataset that define the cost or profit a bank can expect if the borrower defaults or repays their loan.\n\nX_train['profit'] = X_train[\"loan_amnt\"]*(1+0.25*(X_train['loan_int_rate']/100))**10 - X_train['loan_amnt']\nX_train['cost'] = X_train['loan_amnt']*(1+0.25*(X_train['loan_int_rate']/100))**3 - (1.7*X_train['loan_amnt'])\n\nAfter computing the profit likelihoods, the projected profit, and the projected cost of each loan applicant, I was then able to search for the optimal threshold by defining a function that would calculate the expected total profit of the bank if it made loan approval decisions on my profit likelihood feature using a given threshold. This function works by using the threshold to either approve or deny the loan application (0 if approve, 1 if deny, as this will match up with our y_train labels). This approval is calculated by testing whether the profit_likeli is greater than the given threshold. Then, if the approved loans are correct (match up with the actual y_train label), the expected profit will be added to the total; if the approved loans are incorrect (contradict the actual y_train labels), the expected cost will instead be added to the total.\n\ndef calculate_profit(threshold, df, y):\n    df['expect_default'] = np.where(df['profit_likeli'] &gt; threshold, 0, 1)\n    df['correct'] = np.where(df['expect_default'] == y, 1, 0)\n\n    approved = df[df['expect_default'] == 0]\n\n    return np.where(approved['correct'] == 1, approved['profit'], approved['cost']).sum()\n\nBelow, I graphed the expected profits of my model over 1000 different thresholds between 0 and 1. It appears that the optimal thresholds is somewhere close to 0.6.\n\nthresholds = np.linspace(0, 1, 1000)\nexpected_profits = [calculate_profit(threshold, X_train, y_train) for threshold in thresholds]\n\nplt.plot(thresholds, expected_profits)\nplt.title(\"Threshold Values vs. Profit\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Profit (in tens of millions)\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nI then used the ‘optimize’ object from the scipy Python library to find the exact value of the optimal threshold, and the resulting maximimum profit.\n\nfrom scipy import optimize\n\nmaximize_func = lambda x: -calculate_profit(x, X_train, y_train)\n\nmaximization = optimize.minimize_scalar(maximize_func, bounds= (0, 1))\nprint(\"The optimum threshold is: \" + str(maximization.x))\nprint(\"The optimal profit, using the threshold, is: \" + str(round(-maximize_func(maximization.x), 2)))\n\nThe optimum threshold is: 0.6047470824523239\nThe optimal profit, using the threshold, is: 30850532.36\n\n\nSince there were 22,907 data points that I trained my model on, and the profit expected using my optimal threshold was 30,850,532.36, my estimate of the bank’s expected profit per borrower on the training set is 1346.77 dollars in profit per borrower.\n\n\nPart E: Evaluate Model From the Bank’s Perspective\nNow I will test my finalized weight vector and optimal threshold against the test set.\n\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\nI performed the same data pre-processing steps on the testing data as I did to the training data, and then calculated the expected profit of the bank on the testing data using my trained model and optimal threshold.\n\nbins= [0, 30, 50, 70, 90, 150]\nlabels= [\"&lt;30\", \"30-50\", \"50-70\", \"70-90\", \"90+\"]\ndf_test['person_age_group'] = pd.cut(df_test[\"person_age\"], bins=bins, labels=labels, right=False)\n\nX_test, y_test = prepare_data(df_test)\n\ntest_preds = LR.predict_proba(X_test[features])\nX_test[\"profit_likeli\"] = test_preds[:, 0]\n\nX_test['profit'] = X_test[\"loan_amnt\"]*(1+0.25*(X_test['loan_int_rate']/100))**10 - X_test['loan_amnt']\nX_test['cost'] = X_test['loan_amnt']*(1+0.25*(X_test['loan_int_rate']/100))**3 - (1.7*X_test['loan_amnt'])\n\nexpected = calculate_profit(maximization.x, X_test, y_test)\n\nprint(\"The expected profit per borrower on the test set is: \" + str(round(expected / X_test.shape[0], 2)))\n\nThe expected profit per borrower on the test set is: 1273.62\n\n\n\n\nPart F: Evaluate Model From the Borrower’s Perspective\nQuestion 1: Is it more difficult for people in certain age groups to access credit under my proposed system?\nFortunately, in my earlier data preprocessing, I have already given each loan applicant an age group designation, so it should be fairly simple to answer this question.\n\nX_test['person_age_group'] = pd.cut(df_test[\"person_age\"], bins=bins, labels=labels, right=False)\nX_test.groupby('person_age_group')['expect_default'].aggregate(np.mean)\n\nC:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_44992\\2666120760.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  X_test.groupby('person_age_group')['expect_default'].aggregate(np.mean)\nC:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_44992\\2666120760.py:2: FutureWarning: The provided callable &lt;function mean at 0x000001484D709790&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  X_test.groupby('person_age_group')['expect_default'].aggregate(np.mean)\n\n\nperson_age_group\n&lt;30      0.175320\n30-50    0.153194\n50-70    0.166667\n70-90    0.500000\n90+           NaN\nName: expect_default, dtype: float64\n\n\nWith this summary table, we can see the model’s interpretation of the average likelihood across age groups that a loan applicant will default on their loan payment, and therefore should be denied access to the bank’s credit. It looks like the model believes the age group of 70-90 to be the riskiest by far, and then those who are &lt;30 have a 17.53% expected chance of defaulting, followed by a 16.67% chance for those 50-70, and finally a 15.32% chance for those 30-50. However, as we have seen in the data exploration section of this blog post, the number of people in each age group in this data set is heavily skewed, with there being many more loan applicants on the younger side. Thus, it could be said that if there were more applicants in the 70-90 range, the model would assess their risk to be comparable to the other age groups, as opposed to the current outlier of 50% expected risk of default.\nQuestion 2: Is it more difficult for people to get loans in order to pay for medical expenses? How does this compare with the actual rate of default in that group? What about people seeking loans for business ventures or education?\n\nX_test.groupby('loan_intent_MEDICAL')['expect_default'].aggregate(np.mean)\n\nC:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_44992\\29578798.py:1: FutureWarning: The provided callable &lt;function mean at 0x000001484D709790&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  X_test.groupby('loan_intent_MEDICAL')['expect_default'].aggregate(np.mean)\n\n\nloan_intent_MEDICAL\nFalse    0.160155\nTrue     0.209692\nName: expect_default, dtype: float64\n\n\nIt appears that my model on average assigns a loan default risk score of 5% higher to those applying for a loan to pay off medical expenses than applicants intending to use the loan for other purposes.\n\ndf_test.groupby('loan_intent')['loan_status'].aggregate(np.mean)\n\nC:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_44992\\3309084637.py:1: FutureWarning: The provided callable &lt;function mean at 0x000001484D709790&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  df_test.groupby('loan_intent')['loan_status'].aggregate(np.mean)\n\n\nloan_intent\nDEBTCONSOLIDATION    0.279497\nEDUCATION            0.167421\nHOMEIMPROVEMENT      0.246088\nMEDICAL              0.281553\nPERSONAL             0.219227\nVENTURE              0.145701\nName: loan_status, dtype: float64\n\n\nWhile my model’s expected default rate for medical expense loans is lower than the true default rate for medical expense loans (21% vs. 28%), it does reflect the fact that medical expense loans are more likely to be defaulted on than any other loan purposes.\n\nX_test.groupby('loan_intent_EDUCATION')['expect_default'].aggregate(np.mean)\n\nC:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_44992\\4235614756.py:1: FutureWarning: The provided callable &lt;function mean at 0x000001484D709790&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  X_test.groupby('loan_intent_EDUCATION')['expect_default'].aggregate(np.mean)\n\n\nloan_intent_EDUCATION\nFalse    0.167728\nTrue     0.176020\nName: expect_default, dtype: float64\n\n\n\nX_test.groupby('loan_intent_VENTURE')['expect_default'].aggregate(np.mean)\n\nC:\\Users\\oscar\\AppData\\Local\\Temp\\ipykernel_44992\\4016549862.py:1: FutureWarning: The provided callable &lt;function mean at 0x000001484D709790&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n  X_test.groupby('loan_intent_VENTURE')['expect_default'].aggregate(np.mean)\n\n\nloan_intent_VENTURE\nFalse    0.173904\nTrue     0.147303\nName: expect_default, dtype: float64\n\n\nFurthermore, my model’s assessment of the risk score for loan applications for the purposes of education or business ventures is far lower than those for medical expenses (17.6% and 14.7% respectively, against 21%). However, the model’s risk score more accurately represents the true default rate of these two demographics, while the model’s score for medical expense loans is, counterintuitively, lower than the true loan default rate. Perhaps this reflects the fact that my model uses the features of loan amount and applicant’s income to a greater weight than loan intent when making an approval prediction.\nQuestion 3: How does a person’s income level impact the ease with which they can access credit under my decision system?\n\nplot4 = sns.catplot(data= X_test, x= 'expect_default', y= 'person_income', kind= 'boxen')\nplot4.set(yscale= 'log')\nplot4.set(xlabel= \"Expected Default (Model)\", ylabel= \"Income (Log Scale)\", title= 'Predicted Default vs. Income')\nplot4\n\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nc:\\Users\\oscar\\anaconda3\\envs\\ml-0451\\lib\\site-packages\\seaborn\\categorical.py:1794: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\n\n\n\n\n\n\n\n\nUsing this graph, it appears that there is a large influence that a loan applicant’s income has on the model’s assessment of whether the loan is expected to default or not. The higher a person’s income is, the more likely that the model will not predict a default on loan payment. Since the scale used for income is a logarithmic scale, this advantage is likely starker than it initially appears in this visualization.\n\n\nDiscussion\nIn summary, this blog post has detailed the development and application of a machine learning-based logistic regression model for loan risk assessment and decision-making in the banking sector. Through the analysis of various applicant features, the model assigns risk scores to quantify applicants based on their expected risk of defaulting on a loan. Importantly, the post highlights the utility of threshold optimization for loan approval, showing how a bank could calculate the optimal balance between risk mitigation and profit maximization. My model gave the most importance to the data features of loan amount and applicant’s income when assessing whether the loan applicant will default on payments.\nI define fairness as the equality of opportunity between individuals with similar features, not considering features that exist outside of their sphere of control. For example, if a bank is considering two identical applicants, but one has defaulted on a loan in the past, and the other has not, I believe that it would be considered ‘fair’ for a bank to deny the loan for the applicant with a history of defaulting, as the past loan default would be a feature of an applicant that they have control over.\nHowever, I believe that this conception of ‘fairness’ is put at odds with the very notion of machine learning, in that this model’s main goal is to use historical data from many distinct loan applicants to predict the likelihood of repayment from a new applicant. In essence, this process relies heavily on features and data that lay outside the sphere of control of the new applicant, and uses this information in the decision process of loan approval. Simply because many applicants who seek loans for medical expenses have high rates of default, it will be far more difficult for new applicants seeking a loan for medical expenses to access credit. This does not adhere to my conception of fairness, as the new applicant has no control over whether the past loan applicants defaulted on or repaid their loans. Unfortunately, the use of historical data in prediction is one of the best tools available for banks to determine loan repayment success in new applicants and maximize profits."
  },
  {
    "objectID": "posts/PenguinsPost/index.html",
    "href": "posts/PenguinsPost/index.html",
    "title": "Classifying Palmer’s Penguins",
    "section": "",
    "text": "In this blog post I am hoping to find features within the given Palmer Penguins data set that will allow a machine learning model to distinguish penguins of different species. The data set, collected by Dr. Kristen Gorman and the Palmer Station in Antarctica, contains physiological measurements from a sample set of penguins that belong to three different species: Chinstrap, Gentoo, and Adelie. At the end of my exploration and model training, I decided to train my model on the following three features: the Island on which the penguin was found, the penguin’s Culmen Length in millimeters, and the penguin’s Culmen Depth in millimeters. Trained on these three features, my linear regression model was able to predict the species of a given penguin in the data set with 100% accuracy.\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\nX_train.head(20)\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n5\n41.1\n18.2\n192.0\n4050.0\n8.62264\n-26.60023\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n7\n34.6\n21.1\n198.0\n4400.0\n8.55583\n-25.22588\nFalse\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n8\n52.8\n20.0\n205.0\n4550.0\n9.25177\n-24.69638\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n11\n47.2\n15.5\n215.0\n4975.0\n8.30817\n-26.21651\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n13\n46.1\n18.2\n178.0\n3250.0\n8.85664\n-24.55644\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n14\n34.0\n17.1\n185.0\n3400.0\n8.01485\n-26.69543\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n15\n49.7\n18.6\n195.0\n3600.0\n9.75486\n-24.31198\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n16\n41.1\n17.5\n190.0\n3900.0\n8.94365\n-26.06943\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n17\n58.0\n17.8\n181.0\n3700.0\n9.14382\n-24.57994\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\n\n\n18\n46.9\n16.6\n192.0\n2700.0\n9.80589\n-24.73735\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\n\n\n19\n45.7\n13.9\n214.0\n4400.0\n8.62870\n-26.60484\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n20\n42.1\n19.1\n195.0\n4000.0\n9.05736\n-25.81513\nFalse\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n23\n49.1\n14.8\n220.0\n5150.0\n7.89744\n-26.63405\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n24\n48.1\n15.1\n209.0\n5500.0\n8.45738\n-26.22664\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n25\n42.9\n13.1\n215.0\n5000.0\n7.68528\n-25.39181\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse"
  },
  {
    "objectID": "posts/PenguinsPost/index.html#abstract",
    "href": "posts/PenguinsPost/index.html#abstract",
    "title": "Classifying Palmer’s Penguins",
    "section": "",
    "text": "In this blog post I am hoping to find features within the given Palmer Penguins data set that will allow a machine learning model to distinguish penguins of different species. The data set, collected by Dr. Kristen Gorman and the Palmer Station in Antarctica, contains physiological measurements from a sample set of penguins that belong to three different species: Chinstrap, Gentoo, and Adelie. At the end of my exploration and model training, I decided to train my model on the following three features: the Island on which the penguin was found, the penguin’s Culmen Length in millimeters, and the penguin’s Culmen Depth in millimeters. Trained on these three features, my linear regression model was able to predict the species of a given penguin in the data set with 100% accuracy.\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\n\nX_train.head(20)\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n5\n41.1\n18.2\n192.0\n4050.0\n8.62264\n-26.60023\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n7\n34.6\n21.1\n198.0\n4400.0\n8.55583\n-25.22588\nFalse\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n8\n52.8\n20.0\n205.0\n4550.0\n9.25177\n-24.69638\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n11\n47.2\n15.5\n215.0\n4975.0\n8.30817\n-26.21651\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n13\n46.1\n18.2\n178.0\n3250.0\n8.85664\n-24.55644\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n14\n34.0\n17.1\n185.0\n3400.0\n8.01485\n-26.69543\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n15\n49.7\n18.6\n195.0\n3600.0\n9.75486\n-24.31198\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n16\n41.1\n17.5\n190.0\n3900.0\n8.94365\n-26.06943\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n17\n58.0\n17.8\n181.0\n3700.0\n9.14382\n-24.57994\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\n\n\n18\n46.9\n16.6\n192.0\n2700.0\n9.80589\n-24.73735\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\n\n\n19\n45.7\n13.9\n214.0\n4400.0\n8.62870\n-26.60484\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n20\n42.1\n19.1\n195.0\n4000.0\n9.05736\n-25.81513\nFalse\nFalse\nTrue\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n23\n49.1\n14.8\n220.0\n5150.0\n7.89744\n-26.63405\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n24\n48.1\n15.1\n209.0\n5500.0\n8.45738\n-26.22664\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n25\n42.9\n13.1\n215.0\n5000.0\n7.68528\n-25.39181\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse"
  },
  {
    "objectID": "posts/PenguinsPost/index.html#explore",
    "href": "posts/PenguinsPost/index.html#explore",
    "title": "Classifying Palmer’s Penguins",
    "section": "Explore:",
    "text": "Explore:\nIn this section, I will construct and discuss a few interesting data visualizations so that we can better understand the Palmer’s Penguins dataset and what features we may be looking for.\n\nplot1 = sns.scatterplot(data = X_train, x = 'Culmen Length (mm)', \n    y = 'Culmen Depth (mm)', hue = y_train, \n    style = y_train, palette = \"dark\")\nplot1.set_title(\"Culmen Depth vs. Culmen Length\")\nplot1.legend(title = \"Species\")\n\n\n\n\n\n\n\n\nThis scatterplot seems to indicate a heavy correlation between a penguin’s culmen depth and length, and the penguin’s species classification. One species seems to have short and moderately deep culmens (Species 0), another has moderately long and deep culmens (Species 1), and the last species has moderately long and shallow culmens (Species 2).\n\nplot2 = sns.scatterplot(\n    data = X_train, x = 'Culmen Depth (mm)', \n    y = 'Flipper Length (mm)', hue = y_train, \n    style = y_train, palette = \"dark\")\nplot2.set_title(\"Flipper Length vs. Culmen Depth\")\nplot2.legend(title = \"Species\")\nplot2\n\n\n\n\n\n\n\n\nPursuing the lead from the last scatter plot, I decided to plot culmen depth against flipper length, which I predicted would be species-specific, in that it is likely that different species vary noticeably in flipper length. As we saw in the last plot, Species 0 and 1 have similar culmen depths. Additionally, they also seem to have similar flipper lengths, and are therefore very closely plotted in this comparison. However, Species 2 is distinct from the other species by both flipper length and culmen depth, and are thus greatly removed from the other groups in the top left corner of this plot. This points to the fact that Species 2 generally has longer flippers and shallower culmens than the other species, so much so, that they are easily separable in this comparison.\n\nplot3 = sns.boxplot(\n        data = X_train, x = y_train, \n        y = 'Culmen Length (mm)')\nplot3.set_xlabel(\"Species\")\nplot3.set_title(\"Culmen Length Distribution Across Species\")\nplot3\n\n\n\n\n\n\n\n\nReturning to the culmen length variable, we can plot its distribution across species. We can see that this variable generally distinguishes Species 0 from the other two species, in that Species 0 has a shorter culmen than both other species, which have similar culmen lengths. This points to the idea that culmen length is a good feature to use to distinguish penguins of Species 0.\n\nrow1 = X_train.query(\"Island_Biscoe == True\").mean()\nrow2 = X_train.query(\"Island_Dream == True\").mean()\nrow3 = X_train.query(\"Island_Torgersen == True\").mean()\ntable1 = pd.DataFrame([row1, row2, row3])\ntable1\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n44.945600\n15.863200\n209.320000\n4702.000000\n8.394096\n-26.086192\n1.0\n0.0\n0.0\n1.0\n0.072000\n0.928000\n0.520000\n0.480000\n\n\n1\n44.527835\n18.307216\n193.628866\n3734.793814\n9.163175\n-25.075329\n0.0\n1.0\n0.0\n1.0\n0.123711\n0.876289\n0.525773\n0.474227\n\n\n2\n39.350000\n18.441176\n192.235294\n3727.941176\n8.844635\n-25.748135\n0.0\n0.0\n1.0\n1.0\n0.205882\n0.794118\n0.470588\n0.529412\n\n\n\n\n\n\n\nFinally, here is a summary table that groups penguins by their island, and analyzes the average quantitative features of the penguin whose data were collected on the different islands. On takeaway is that the penguins found on Island Torgersen have shorter culmens than those on the other islands. Another is that the penguins on Island Boscoe have shallower culmens than those found on the other islands. Additionally, penguins on Island Boscoe are larger (with greater flipper length and body mass). Through these comparisons, it looks like the island on which a penguin is found can be a good indicator of what species the penguin may be. This is because there seems to be a greater concentration of feature variance across islands, i.e. Boscoe has larger penguins with shallow culmens, and Torgersen has penguins with longer culmens. I predict that the best features to distinguish penguins will be Culmen Length, Culmen Depth, Island, and Flipper Length/Body Mass."
  },
  {
    "objectID": "posts/PenguinsPost/index.html#model",
    "href": "posts/PenguinsPost/index.html#model",
    "title": "Classifying Palmer’s Penguins",
    "section": "Model:",
    "text": "Model:\nIn this section, I will find three features of the data and train a model on these features which achieves a 100% testing accuracy.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\nfrom sklearn.model_selection import cross_val_score\n\nHere, I am testing every possible permutation of one qualitative feature and two quantitative features, and training a model on each permutation. I will use the model that shows the best average accuracy according to cross validation.\n\nfrom itertools import combinations\n\n# these are not actually all the columns: you'll \n# need to add any of the other ones you want to search for\nall_qual_cols = [\"Clutch Completion\", \"Island\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)']\nLR = LogisticRegression(max_iter=10000)\n\nfeature_comparison = pd.DataFrame(columns=['Features', 'Accuracy'])\n\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair) \n    LR.fit(X_train[cols], y_train)\n    avg_score = np.mean(cross_val_score(LR, X_train[cols], y_train, cv = 5))\n    \n    # I'm trying to put all results into a table, and then sort by score\n    feature_comparison.loc[len(feature_comparison)] = {'Features' : cols, 'Accuracy' : avg_score}\n\n\nbest_features = feature_comparison.sort_values('Accuracy', ascending = False).head(5)\nbest_features\n\n\n\n\n\n\n\n\nFeatures\nAccuracy\n\n\n\n\n15\n[Island_Biscoe, Island_Dream, Island_Torgersen...\n0.988311\n\n\n17\n[Island_Biscoe, Island_Dream, Island_Torgersen...\n0.972624\n\n\n19\n[Island_Biscoe, Island_Dream, Island_Torgersen...\n0.964932\n\n\n26\n[Island_Biscoe, Island_Dream, Island_Torgersen...\n0.964857\n\n\n18\n[Island_Biscoe, Island_Dream, Island_Torgersen...\n0.964857\n\n\n\n\n\n\n\nThese are the features used by the most accurate model.\n\nbest_features['Features'].iloc[0]\n\n['Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen',\n 'Culmen Length (mm)',\n 'Culmen Depth (mm)']\n\n\n\nfit_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', \n            'Island_Dream', 'Island_Torgersen']\n\nThis is the training accuracy of the best model.\n\nLR.fit(X_train[fit_cols], y_train)\nLR.score(X_train[fit_cols], y_train)\n\n0.99609375"
  },
  {
    "objectID": "posts/PenguinsPost/index.html#evaluate",
    "href": "posts/PenguinsPost/index.html#evaluate",
    "title": "Classifying Palmer’s Penguins",
    "section": "Evaluate:",
    "text": "Evaluate:\nIn this section, I will show the decision boundaries of my model, split out by the qualitative feature.\nFirst, here is the model’s testing accuracy, it is 100% correct.\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nLR.score(X_test[fit_cols], y_test)\n\n1.0\n\n\n\nfrom matplotlib.patches import Patch\nfrom matplotlib import pyplot as plt\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # create a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\n\nplot_regions(LR, X_train[fit_cols], y_train)\n\n\n\n\n\n\n\n\n\nfrom sklearn.metrics import confusion_matrix\ny_test_pred = LR.predict(X_test[fit_cols])\n\nC = confusion_matrix(y_test, y_test_pred)\nC\n\narray([[31,  0,  0],\n       [ 0, 11,  0],\n       [ 0,  0, 26]], dtype=int64)\n\n\nAccording to the confusion matrix, my model seems to have performed perfectly on the testing data, and produced no errors in the classification."
  },
  {
    "objectID": "posts/PenguinsPost/index.html#discussion",
    "href": "posts/PenguinsPost/index.html#discussion",
    "title": "Classifying Palmer’s Penguins",
    "section": "Discussion",
    "text": "Discussion\nI performed cross validation on logistic regression models trained on every combination of 3 qualitative/quantitative features found within the Palmer’s Penguins data set. The model that performed the best (to 99.6% training accuracy) was trained on the features Island, Culmen Length, and Culmen Depth, and performed with a 100% testing accuracy. I think that if I were to explore this assignment further, I would like to experiment with other classification models, to see if there are ways to classify this data set with comparable accuracy, but using fewer features."
  }
]